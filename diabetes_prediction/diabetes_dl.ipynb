{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f71b1fb3-9ab8-4f23-a9eb-3f1049543c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f88d2689-77bb-412b-823f-21932f8eea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "scale_col = ['physical_activity_minutes_per_week','diet_score','sleep_hours_per_day','screen_time_hours_per_day','bmi','waist_to_hip_ratio',\n",
    "             'systolic_bp','diastolic_bp','heart_rate','cholesterol_total','hdl_cholesterol','ldl_cholesterol','triglycerides']\n",
    "encode_col = ['gender','ethnicity','education_level','income_level',\n",
    "              'smoking_status','employment_status']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "def train_scale_encode_process(df,scale_col,encode_col):\n",
    "    scalers = {}\n",
    "    encoders = {}\n",
    "    for col in scale_col:\n",
    "        scaler = MinMaxScaler()\n",
    "        df['scale_'+col] = scaler.fit_transform(df[[col]])\n",
    "        scalers[col] = scaler\n",
    "        df = df.drop(columns = col)\n",
    "    for col in encode_col:\n",
    "        encoder = LabelEncoder()\n",
    "        df['encode_'+col] = encoder.fit_transform(df[[col]])\n",
    "        encoders[col] = encoder\n",
    "        df = df.drop(columns = col)\n",
    "    df = df.drop(columns = ['id']).reset_index(drop = True)\n",
    "    return df,scalers,encoders\n",
    "def pred_encode_scale_process(df_pred,scale_col,encode_col,scalers,encoders):\n",
    "    for col in scale_col:\n",
    "        scaler = scalers[col]\n",
    "        df_pred['scale_'+col] = scaler.transform(df_pred[[col]])\n",
    "        df_pred = df_pred.drop(columns = col)\n",
    "    for col in encode_col:\n",
    "        encoder = encoders[col]\n",
    "        df_pred['encode_'+col] = encoder.transform(df_pred[[col]])\n",
    "        df_pred = df_pred.drop(columns = col)\n",
    "    df_pred= df_pred.drop(columns = ['id']).reset_index(drop = True)\n",
    "    return df_pred\n",
    "train,scalers,encoders = train_scale_encode_process(df_train,scale_col,encode_col)\n",
    "pred = pred_encode_scale_process(df_test,scale_col,encode_col,scalers,encoders)\n",
    "x_col = list(train.columns)\n",
    "y_col = 'diagnosed_diabetes'\n",
    "x_col.remove('diagnosed_diabetes')\n",
    "x = train[x_col]\n",
    "y = train[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e19ee00-fba4-461b-8a08-29ad3c27c5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433ca56c-d119-40da-b96e-66e2ff0efff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_label,test_label = train_test_split(x,y,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a459136-e7ab-43b2-8815-f0b5135869d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e530902-3f1c-4b8f-a2c3-970a91e07097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 6.0418 - val_accuracy: 0.6241 - val_loss: 5.9931\n",
      "Epoch 2/15\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6225 - loss: 6.0158 - val_accuracy: 0.6241 - val_loss: 5.9931\n",
      "Epoch 3/15\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 6.0086 - val_accuracy: 0.6241 - val_loss: 5.9931\n",
      "Epoch 4/15\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 6.0085 - val_accuracy: 0.6241 - val_loss: 5.9931\n",
      "Epoch 5/15\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.6231 - loss: 6.0084 - val_accuracy: 0.6241 - val_loss: 5.9931\n",
      "Epoch 6/15\n",
      "\u001b[1m4375/4375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 6.0091 - val_accuracy: 0.6241 - val_loss: 5.9931\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m9375/9375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 729us/step\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model = Sequential([\n",
    "    Dense(256, input_dim = train_data.shape[1], activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation = 'relu'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "es = EarlyStopping(\n",
    "    monitor = 'accuracy',\n",
    "    min_delta = 0.0001,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "# 模型訓練\n",
    "history = model.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(test_data, test_label),\n",
    "    epochs=15,  # 訓練 50 個世代，可調整\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    callbacks = [es]\n",
    ")\n",
    "\n",
    "# 測試集預測\n",
    "predictions = model.predict(pred)\n",
    "predictions = (predictions > 0.5).astype(int)  # 大於 0.5 的預測為 1 (有糖尿病診斷)\n",
    "\n",
    "# 輸出預測結果\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981acf9-d70e-4832-a52b-5edba6c9c4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
