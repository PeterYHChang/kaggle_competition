{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6b00bf-2667-4b14-90e6-13e5a3aba18f",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42cd0533-1b61-4ecc-ba44-d9ea7e7b143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c927a04-8a85-4040-8c93-919061022272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'store-sales-time-series-forecasting\\train.csv')\n",
    "holiday_events = pd.read_csv(r'store-sales-time-series-forecasting\\holidays_events.csv')\n",
    "stores = pd.read_csv(r'store-sales-time-series-forecasting\\stores.csv')\n",
    "test = pd.read_csv(r'store-sales-time-series-forecasting\\test.csv')\n",
    "oil = pd.read_csv(r'store-sales-time-series-forecasting\\oil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2167c2f1-0b15-48d1-8a76-4af2775524d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>47.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>46.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>46.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>45.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>47.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  dcoilwtico\n",
       "0     2013-01-01         NaN\n",
       "1     2013-01-02       93.14\n",
       "2     2013-01-03       92.97\n",
       "3     2013-01-04       93.12\n",
       "4     2013-01-07       93.20\n",
       "...          ...         ...\n",
       "1213  2017-08-25       47.65\n",
       "1214  2017-08-28       46.40\n",
       "1215  2017-08-29       46.46\n",
       "1216  2017-08-30       45.96\n",
       "1217  2017-08-31       47.26\n",
       "\n",
       "[1218 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0655b1eb-717f-4ccf-8d6d-2f1e2664c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,stores,holiday_events,oil):\n",
    "    # --- deal store data\n",
    "    merged_df = pd.merge(df, stores, on=\"store_nbr\", how=\"left\")\n",
    "    merged_df = merged_df.drop(columns=['type','cluster','id'])\n",
    "    # --- deal holiday data\n",
    "    holiday_df = holiday_events[holiday_events['transferred']==False]\n",
    "    holiday_df['is_holiday'] = 1\n",
    "    holiday_df = holiday_df[['date','is_holiday']].drop_duplicates(subset='date')\n",
    "    merged_df = pd.merge( merged_df, holiday_df, on = \"date\", how = \"left\")\n",
    "    merged_df['is_holiday'] = merged_df['is_holiday'].fillna(0).astype(int)\n",
    "    # --- deal oil data\n",
    "    merged_df = pd.merge( merged_df, oil, on = \"date\", how = \"left\")\n",
    "    merged_df['dcoilwtico'] = merged_df['dcoilwtico'].fillna(0)\n",
    "    # --- add day and weekend key\n",
    "    merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "    merged_df['day'] = merged_df[\"date\"].dt.day\n",
    "    merged_df['month'] = merged_df[\"date\"].dt.month\n",
    "    merged_df['year'] = merged_df[\"date\"].dt.year\n",
    "    merged_df['is_weekend'] = merged_df['date'].apply(lambda x : 1 if x.dayofweek>=5 else 0)\n",
    "    return merged_df\n",
    "merged_train = process_data(train,stores,holiday_events,oil)\n",
    "merged_test = process_data(test,stores,holiday_events,oil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d4ec47-49ea-4bea-9704-67e1e2f4fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000883</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000884</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000885</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000886</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000887</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000888 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr                      family     sales  \\\n",
       "0       2013-01-01          1                  AUTOMOTIVE     0.000   \n",
       "1       2013-01-01          1                   BABY CARE     0.000   \n",
       "2       2013-01-01          1                      BEAUTY     0.000   \n",
       "3       2013-01-01          1                   BEVERAGES     0.000   \n",
       "4       2013-01-01          1                       BOOKS     0.000   \n",
       "...            ...        ...                         ...       ...   \n",
       "3000883 2017-08-15          9                     POULTRY   438.133   \n",
       "3000884 2017-08-15          9              PREPARED FOODS   154.553   \n",
       "3000885 2017-08-15          9                     PRODUCE  2419.729   \n",
       "3000886 2017-08-15          9  SCHOOL AND OFFICE SUPPLIES   121.000   \n",
       "3000887 2017-08-15          9                     SEAFOOD    16.000   \n",
       "\n",
       "         onpromotion   city      state  is_holiday  dcoilwtico  day  month  \\\n",
       "0                  0  Quito  Pichincha           1        0.00    1      1   \n",
       "1                  0  Quito  Pichincha           1        0.00    1      1   \n",
       "2                  0  Quito  Pichincha           1        0.00    1      1   \n",
       "3                  0  Quito  Pichincha           1        0.00    1      1   \n",
       "4                  0  Quito  Pichincha           1        0.00    1      1   \n",
       "...              ...    ...        ...         ...         ...  ...    ...   \n",
       "3000883            0  Quito  Pichincha           1       47.57   15      8   \n",
       "3000884            1  Quito  Pichincha           1       47.57   15      8   \n",
       "3000885          148  Quito  Pichincha           1       47.57   15      8   \n",
       "3000886            8  Quito  Pichincha           1       47.57   15      8   \n",
       "3000887            0  Quito  Pichincha           1       47.57   15      8   \n",
       "\n",
       "         year  is_weekend  \n",
       "0        2013           0  \n",
       "1        2013           0  \n",
       "2        2013           0  \n",
       "3        2013           0  \n",
       "4        2013           0  \n",
       "...       ...         ...  \n",
       "3000883  2017           0  \n",
       "3000884  2017           0  \n",
       "3000885  2017           0  \n",
       "3000886  2017           0  \n",
       "3000887  2017           0  \n",
       "\n",
       "[3000888 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f34a065-5542-469f-b1a8-ee1fd09186b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "def encode_scale(df, encode_col, scale_col):\n",
    "    encode = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "    for col in encode_col:\n",
    "        df['encode_'+col] = encode.fit_transform(df[col])\n",
    "    for col in scale_col:\n",
    "        df['scale_'+col] = scaler.fit_transform(df[[col]])\n",
    "    return df,encode,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86989453-1b94-4727-846f-271306610c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_col = ['family']\n",
    "scale_col = ['onpromotion','dcoilwtico']\n",
    "pro_df,encode,scaler = encode_scale(merged_train, encode_col, scale_col)\n",
    "pro_df = pro_df.drop(columns=['date','family','onpromotion','city','state','dcoilwtico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d85aec5c-cb9e-4f13-ac63-fe93364e7c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>encode_family</th>\n",
       "      <th>scale_dcoilwtico</th>\n",
       "      <th>scale_onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.235870</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.235870</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.235870</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.235870</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.235870</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000883</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000884</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>-0.131172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000885</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>11.899391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000886</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>0.441712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000887</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>-0.213012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000888 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         month  day  store_nbr  is_holiday  is_weekend  encode_family  \\\n",
       "0            1    1          1           1           0              0   \n",
       "1            1    1          1           1           0              1   \n",
       "2            1    1          1           1           0              2   \n",
       "3            1    1          1           1           0              3   \n",
       "4            1    1          1           1           0              4   \n",
       "...        ...  ...        ...         ...         ...            ...   \n",
       "3000883      8   15          9           1           0             28   \n",
       "3000884      8   15          9           1           0             29   \n",
       "3000885      8   15          9           1           0             30   \n",
       "3000886      8   15          9           1           0             31   \n",
       "3000887      8   15          9           1           0             32   \n",
       "\n",
       "         scale_dcoilwtico  scale_onpromotion  \n",
       "0               -1.235870          -0.213012  \n",
       "1               -1.235870          -0.213012  \n",
       "2               -1.235870          -0.213012  \n",
       "3               -1.235870          -0.213012  \n",
       "4               -1.235870          -0.213012  \n",
       "...                   ...                ...  \n",
       "3000883          0.017372          -0.213012  \n",
       "3000884          0.017372          -0.131172  \n",
       "3000885          0.017372          11.899391  \n",
       "3000886          0.017372           0.441712  \n",
       "3000887          0.017372          -0.213012  \n",
       "\n",
       "[3000888 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_col = ['month','day','store_nbr', 'is_holiday', 'is_weekend', 'encode_family', 'scale_dcoilwtico', 'scale_onpromotion']\n",
    "pro_df[feature_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1a96ec-d6b4-4272-b85f-cdb9e3baec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x: 3000888\n",
      "Length of y: 3000888\n",
      "x_train shape: (2400710, 8)\n",
      "y_train shape: (2400710,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = pro_df[feature_col]\n",
    "y = pro_df['sales']\n",
    "print(\"Length of x:\", len(x))\n",
    "print(\"Length of y:\", len(y))\n",
    "\n",
    "# 確保數據一致無遺漏問題\n",
    "if len(x) == len(y):\n",
    "    # 分割數據集\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 確認分割後形狀\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e7303-9362-4431-9e49-d905c23af873",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a4c32dd-1832-4330-84b3-15a67740e643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  2.71220731  -1.56497878   2.67027139  13.79099891 157.97924979\n",
      " -10.94361805   1.15827077 466.83718912]\n",
      "Intercept: 419.4791697748181\n",
      "Mean Squared Error (MSE): 997361.341920931\n",
      "R-squared (R2): 0.19749610894736358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# x_train,y_train,x_test,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "# 顯示結果\n",
    "print(\"Coefficients:\", model.coef_)  # 特徵的係數\n",
    "print(\"Intercept:\", model.intercept_)  # 截距\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # 均方誤差\n",
    "print(\"R-squared (R2):\", r2)  # R^2 分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adb24dde-f473-4476-bd5d-b95fdde13fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_col = ['family','city','state']\n",
    "scale_col = ['onpromotion']\n",
    "test_df,_,_ = encode_scale(merged_test, encode_col, scale_col)\n",
    "test_df = test_df.drop(columns=['date','family','onpromotion','city','state'])\n",
    "test_df['scale_sales'] = model.predict(test_df)\n",
    "test_df['sales'] = scaler.inverse_transform(test_df[['scale_sales']])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ce5dd3a-fe64-45bb-9479-e266751b13e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combine_df = pd.concat([ test_df.reset_index(drop=True), test.reset_index(drop=True)], axis = 1)[['id','sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bacb4b92-05f9-4110-9958-00e2af0eba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df.to_csv('submission_regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c6d53-276f-4064-a82e-5e602e61e4a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ce11f0f-35ef-4e99-a9e0-c5aaaa3901de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 110455.36576760026\n",
      "R-squared (R2): 0.9111246274640865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 建立並配置 Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=500,       # 樹的數量（可以增加以提升擬合能力，但可能增加計算成本）\n",
    "    max_depth=31,           # 最大樹深度（限制以避免過擬合）\n",
    "    random_state=42,        # 固定隨機狀態保證結果穩定\n",
    "    min_samples_split=10,   # 分裂的最小樣本數\n",
    "    min_samples_leaf=5,     # 葉節點的最小樣本數\n",
    "    n_jobs=-1               # 使用所有處理器並行運算\n",
    ")\n",
    "rf_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred_rf)\n",
    "r2 = r2_score(y_test,y_pred_rf)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)  # 均方誤差\n",
    "print(\"R-squared (R2):\", r2)  # R^2 分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f8dd316-657a-49d3-a8c7-8a85fb243da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_col = ['family']\n",
    "scale_col = ['onpromotion','dcoilwtico']\n",
    "test_df,_,_ = encode_scale(merged_test, encode_col, scale_col)\n",
    "test_df = test_df.drop(columns=['date','family','onpromotion','city','state','dcoilwtico'])[feature_col]\n",
    "test_df['sales'] = rf_model.predict(test_df)\n",
    "combine_df_rf = pd.concat([ test_df.reset_index(drop=True), test.reset_index(drop=True)], axis = 1)[['id','sales']]\n",
    "combine_df_rf['sales'] = combine_df_rf['sales'].apply(lambda x: 0 if x < 0 else x)\n",
    "combine_df_rf.to_csv('submission_randomforest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf1fdf-6967-486b-a9ef-bfd51e950ff2",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ed5399-05d1-4178-b6a7-dc645a5c674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Results:\n",
      "Mean Squared Error (MSE): 242918.62471346091\n",
      "R-squared (R2): 0.8045411092771608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 建立並配置 Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=200,            # 樹的數量（增大可能提升效果，但需注意計算成本）\n",
    "    learning_rate=0.05,           # 學習率（減少可能減低步長，避免過擬合）\n",
    "    max_depth=5,                 # 樹的深度（增加過擬合可能性）\n",
    "    subsample=0.8,               # 每棵樹所使用的子樣本比例（控制過擬合）\n",
    "    random_state=42              # 保持結果穩定\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred_gb = gb_model.predict(x_test)\n",
    "\n",
    "# 評估模型\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# 顯示結果\n",
    "print(\"Gradient Boosting Regressor Results:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse_gb)\n",
    "print(\"R-squared (R2):\", r2_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a80a4e7-66a8-41c2-8b5b-62b33a44f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_col = ['family','city','state']\n",
    "scale_col = ['onpromotion']\n",
    "test_df,_,_ = encode_scale(merged_test, encode_col, scale_col)\n",
    "test_df = test_df.drop(columns=['date','family','onpromotion','city','state'])\n",
    "test_df['scale_sales'] = gb_model.predict(test_df)\n",
    "test_df['sales'] = scaler.inverse_transform(test_df[['scale_sales']])[:, 0]\n",
    "combine_df_rf = pd.concat([ test_df.reset_index(drop=True), test.reset_index(drop=True)], axis = 1)[['id','sales']]\n",
    "combine_df_rf.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3907cf1-8323-4ed4-83bb-2c19fb3d7b53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ace50dc-1aab-4f12-877f-80f8f977e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 603\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400710, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 357.301279\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LGBM Regressor Results:\n",
      "Mean Squared Error (MSE): 192569.30776468528\n",
      "R-squared (R2): 0.8450535304678732\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# 建立並配置 LGBM Regressor\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=500,             # 樹的數量\n",
    "    learning_rate=0.05,           # 學習率\n",
    "    num_leaves=31,                # 每棵樹葉節點的最大數量\n",
    "    max_depth=5,                  # 樹的深度\n",
    "    subsample=0.8,                # 每棵樹使用子樣本比例\n",
    "    random_state=42               # 保持結果穩定\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "lgb_model.fit(x_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred_lgb = lgb_model.predict(x_test)\n",
    "\n",
    "# 評估模型\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
    "\n",
    "# 顯示結果\n",
    "print(\"LGBM Regressor Results:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse_lgb)\n",
    "print(\"R-squared (R2):\", r2_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1973ce8-5834-4b9c-98e3-a338ab269178",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_col = ['family']\n",
    "scale_col = ['onpromotion','dcoilwtico']\n",
    "test_df,_,_ = encode_scale(merged_test, encode_col, scale_col)\n",
    "test_df = test_df.drop(columns=['date','family','onpromotion','city','state','dcoilwtico'])[feature_col]\n",
    "test_df['sales'] = lgb_model.predict(test_df)\n",
    "combine_df_rf = pd.concat([ test_df.reset_index(drop=True), test.reset_index(drop=True)], axis = 1)[['id','sales']]\n",
    "combine_df_rf['sales'] = combine_df_rf['sales'].apply(lambda x: 0 if x < 0 else x)\n",
    "combine_df_rf.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e82963-63d3-434e-ba6e-5e24a570be8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
